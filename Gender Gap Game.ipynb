{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Game is important for forthcoming discussion of the Gender Gap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a game.\n",
    "\n",
    "The rules are very simple.  I'm going to name a sequence of three numbers.  The sequence follows a **secret rule**.\n",
    "\n",
    "You win the game by figuring out the secret rule.\n",
    "\n",
    "In order to figure out the rule, you can submit a sequence of three numbers. I will tell you if your sequence follows the rule or not.\n",
    "\n",
    "You can submit as many sequences as you want.  There is no penalty for submitting sequences that do not follow the rule.  There is no reward for submitting sequences that do follow the rule.\n",
    "\n",
    "When you have evidence that you know what the rule is, you can submit a guess.  **You can only guess once!**  If you guess the rule incorrectly, you will never learn the secret rule.\n",
    "\n",
    "An **example that follows the secret rule is: 2, 4, 6**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit an Ordered Sequence (no penalty for sequences that do not follow the rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.submit_list([4,6,8]) # enter your guess in the brackets, separated by commas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guess the rule (If you guess wrong, you'll never learn the rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true rule: [1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You win!'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.submit_guesses([\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.new_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.python.ops.rnn_cell import DropoutWrapper\n",
    "from tensorflow.python.ops import embedding_ops\n",
    "from tensorflow.python.ops import variable_scope as vs\n",
    "from tensorflow.python.ops import rnn_cell\n",
    "import re\n",
    "from vocab import PAD_ID, UNK_ID, get_glove\n",
    "import pdb  # noqa\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "def split_by_whitespace(sentence):\n",
    "    words = []\n",
    "    for space_separated_fragment in sentence.strip().split():\n",
    "        words.extend(re.split(\" \", space_separated_fragment))\n",
    "    return [w for w in words if w]\n",
    "\n",
    "\n",
    "def sentence_to_token_ids(sentence, word2id):\n",
    "    \"\"\"Turns an already-tokenized sentence string into word indices\n",
    "    e.g. \"i do n't know\" -> [9, 32, 16, 96]\n",
    "    Note any token that isn't in the word2id mapping\n",
    "    gets mapped to the id for UNK\n",
    "    \"\"\"\n",
    "    tokens = split_by_whitespace(sentence)  # list of strings\n",
    "    ids = [word2id.get(w, UNK_ID) for w in tokens]\n",
    "    return tokens, ids\n",
    "\n",
    "\n",
    "def padded(token_batch, batch_pad=0):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      token_batch: List (length batch size) of lists of ints.\n",
    "      batch_pad: Int. Length to pad to. If 0, pad to maximum\n",
    "      length sequence in token_batch.\n",
    "    Returns:\n",
    "      List (length batch_size) of padded of lists of ints.\n",
    "        All are same length - batch_pad if batch_pad!=0,\n",
    "        otherwise the maximum length in token_batch\n",
    "    \"\"\"\n",
    "    maxlen = max(map(lambda x: len(x), token_batch)) if batch_pad == 0 else batch_pad # noqa\n",
    "    # return map(lambda token_list: token_list + [PAD_ID] * (maxlen - len(token_list)), token_batch) # noqa\n",
    "    padded = [lis + [PAD_ID] * (maxlen - len(lis)) for lis in token_batch]\n",
    "    return padded\n",
    "\n",
    "\n",
    "class GameModel(object):\n",
    "    \"\"\"\n",
    "    stores the game state and makes predictions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, id2word, word2id, emb_matrix, rule_length=14):\n",
    "        self.new_game()\n",
    "        self.num_epochs = 2000\n",
    "        self.sess = tf.Session()\n",
    "        self.rule_length = rule_length\n",
    "        self.hidden_size = 100\n",
    "        self.id2word = id2word\n",
    "        self.keep_prob = tf.placeholder_with_default(1.0, shape=(),\n",
    "                                                     name='KEEP_PROB')\n",
    "        self.word2id = word2id\n",
    "        cell_fw = rnn_cell.GRUCell(self.hidden_size)\n",
    "        self.rnn_cell_fw = DropoutWrapper(cell_fw,\n",
    "                                          input_keep_prob=self.keep_prob)\n",
    "        cell_bw = rnn_cell.GRUCell(self.hidden_size)\n",
    "        self.rnn_cell_bw = DropoutWrapper(cell_bw,\n",
    "                                          input_keep_prob=self.keep_prob)\n",
    "        # add all parts of the graph\n",
    "        with tf.variable_scope(\"MODEL\"):\n",
    "            self.add_placeholders()\n",
    "            self.add_embedding_layer(emb_matrix)\n",
    "            self.build_graph()\n",
    "            self.add_loss()\n",
    "\n",
    "        # clip by gradient norm\n",
    "        params = tf.trainable_variables()\n",
    "        self.param_norm = tf.global_norm(params)\n",
    "        gradients = tf.gradients(self.loss, params)\n",
    "        self.gradient_norm = tf.global_norm(gradients)\n",
    "        clipped_gradients, _ = tf.clip_by_global_norm(gradients, 5)\n",
    "\n",
    "        # Define optimizer and return update step\n",
    "        self.global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        opt = tf.train.AdamOptimizer(beta1=0.8)\n",
    "        self.updates = opt.apply_gradients(zip(clipped_gradients, params),\n",
    "                                           global_step=self.global_step)\n",
    "        self.summaries = tf.summary.merge_all()\n",
    "\n",
    "    def new_game(self):\n",
    "        guess_cols = [\"Rule Guess\", \"Penalty\"]\n",
    "        self.guesses = pd.DataFrame(columns=guess_cols)\n",
    "        list_cols = [\"Sequence\", \"Follows Rule\"]\n",
    "        self.lists = pd.DataFrame(columns=list_cols, data=[[str([2, 4, 6]), True]])  # noqa\n",
    "\n",
    "    def add_placeholders(self):\n",
    "        shp = [None, self.rule_length]\n",
    "        self.rule_ids = tf.placeholder(tf.int32, shape=shp, name='RULE_IDS')\n",
    "        self.rule_mask = tf.placeholder(tf.int32, shape=shp, name='RULE_MASK')\n",
    "        self.labels = tf.placeholder(tf.int32, shape=(None), name='LABELS')\n",
    "\n",
    "    def add_embedding_layer(self, emb_matrix):\n",
    "        with tf.variable_scope(\"embedding\"):\n",
    "            embedding_matrix = tf.constant(emb_matrix, dtype=tf.float32,\n",
    "                                           name=\"emb_matrix\")\n",
    "            self.rule_embs = embedding_ops.embedding_lookup(embedding_matrix,\n",
    "                                                            self.rule_ids)\n",
    "\n",
    "    def build_graph(self):\n",
    "        with vs.variable_scope(\"RNNEncoder\"):\n",
    "            input_lens = tf.reduce_sum(self.rule_mask, reduction_indices=1)\n",
    "            _, finals = tf.nn.bidirectional_dynamic_rnn(self.rnn_cell_fw,\n",
    "                                                        self.rnn_cell_bw,\n",
    "                                                        self.rule_embs,\n",
    "                                                        input_lens,\n",
    "                                                        dtype=tf.float32)\n",
    "            (output_state_fw, output_state_bw) = finals\n",
    "            out = output_state_fw + output_state_bw\n",
    "            self.logits = tf.contrib.layers.fully_connected(out, 2)\n",
    "\n",
    "    def add_loss(self):\n",
    "        labels = self.labels\n",
    "        gits = self.logits\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=gits,\n",
    "                                                              labels=labels)\n",
    "        self.loss = tf.reduce_mean(loss, name='Loss')\n",
    "        tf.summary.scalar('loss', self.loss)\n",
    "\n",
    "    def run_train_iter(self, sess, ids, mask, labels, summary_writer):\n",
    "        \"\"\"\n",
    "        This performs a single training iteration\n",
    "        (forward pass, loss computation, backprop, parameter update)\n",
    "        Inputs:\n",
    "          session: TensorFlow session\n",
    "          batch: a Batch object\n",
    "          summary_writer: for Tensorboard\n",
    "        Returns:\n",
    "          loss: The loss (averaged across the batch) for this batch.\n",
    "          global_step: The current number of training iterations we've done\n",
    "          param_norm: Global norm of the parameters\n",
    "          gradient_norm: Global norm of the gradients\n",
    "        \"\"\"\n",
    "        # Match up our input data with the placeholders\n",
    "        input_feed = {}\n",
    "        input_feed[self.rule_ids] = ids\n",
    "        input_feed[self.rule_mask] = mask\n",
    "        input_feed[self.labels] = labels\n",
    "        input_feed[self.keep_prob] = 1.0\n",
    "\n",
    "        # output_feed contains the things we want to fetch.\n",
    "        output_feed = [self.updates,\n",
    "                       self.summaries,\n",
    "                       self.loss,\n",
    "                       self.global_step,\n",
    "                       self.param_norm,\n",
    "                       self.gradient_norm]\n",
    "\n",
    "        # Run the model\n",
    "        out = sess.run(output_feed, feed_dict=input_feed)\n",
    "        [_, summaries, loss, global_step, param_norm, gradient_norm] = out\n",
    "\n",
    "        # All summaries in the graph are added to Tensorboard\n",
    "        summary_writer.add_summary(summaries, global_step)\n",
    "\n",
    "        return loss, global_step, param_norm, gradient_norm\n",
    "\n",
    "    def train(self, descriptions, labels):\n",
    "        # make descriptions into 1 hot id vectors\n",
    "        sess = self.sess\n",
    "        ids, mask = self.get_ids_and_mask(descriptions)\n",
    "        epoch = 0\n",
    "        loss = 1\n",
    "        summary_writer = tf.summary.FileWriter('./', sess.graph)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        while epoch < self.num_epochs and loss > 1e-4:\n",
    "            epoch += 1\n",
    "            trn = self.run_train_iter(sess, ids, mask, labels, summary_writer)\n",
    "            loss, global_step, param_norm, grad_norm = trn\n",
    "            if global_step < 5 or global_step % 100 == 0:\n",
    "                print('epoch: {}>>LOSS: {}\\ngrad norm: {}param_norm: \\\n",
    "                      {}'.format(epoch, loss, grad_norm, param_norm))\n",
    "\n",
    "    def get_predictions(self, session, rule_ids, rule_mask):\n",
    "        input_feed = {}\n",
    "        input_feed[self.rule_ids] = rule_ids\n",
    "        input_feed[self.rule_mask] = rule_mask\n",
    "\n",
    "        output_feed = [self.logits]\n",
    "        dist = session.run(output_feed, input_feed)\n",
    "        pred = np.argmax(dist[0], axis=1)\n",
    "        return pred\n",
    "\n",
    "    def get_ids_and_mask(self, descriptions):\n",
    "        ids = [sentence_to_token_ids(desc, self.word2id)[1] for desc in descriptions]  # noqa\n",
    "        ids = padded(ids, self.rule_length)\n",
    "        ids = np.array(ids)\n",
    "        mask = (ids != PAD_ID).astype(np.int32)\n",
    "        return ids, mask\n",
    "\n",
    "    def submit_guesses(self, rg):\n",
    "        \"\"\"\n",
    "        rg: a guess for the rule\n",
    "        determines whether the rule is correct or not\n",
    "        If the rule is correct, ends the game.\n",
    "        Otherwise, displays the prior guesses\n",
    "        and the penalty\n",
    "        \"\"\"\n",
    "        ids, mask = self.get_ids_and_mask(rg)\n",
    "        true_rule = self.get_predictions(self.sess, ids, mask)\n",
    "        print('true rule: {}'.format(true_rule))\n",
    "        if true_rule[0] == 1:\n",
    "            return \"You win!\"\n",
    "        else:\n",
    "            guess_cols = [\"Rule Guess\", \"Penalty\"]\n",
    "            this_guess = pd.DataFrame(columns=guess_cols, data=[[rg, -1]])\n",
    "            self.guesses = self.guesses.append(this_guess)\n",
    "            return self.guesses\n",
    "\n",
    "    def submit_list(self, seq):\n",
    "        \"\"\"\n",
    "        l: array containing the list\n",
    "        determines whether the list follows the sequence or not\n",
    "        \"\"\"\n",
    "        assert(len(seq) == 3)\n",
    "\n",
    "        def decider(x):\n",
    "            return (x[0] < x[1] and x[1] < x[2])\n",
    "        follows_rule = decider(seq)\n",
    "        list_cols = [\"Sequence\", \"Follows Rule\"]\n",
    "        new_row = pd.DataFrame(columns=list_cols,\n",
    "                               data=[[str(seq), follows_rule]])\n",
    "        self.lists = self.lists.append(new_row)\n",
    "        return self.lists\n",
    "      \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [\"three numbers that increase in their values\",1],\n",
    "    [\"three numbers that are not strictly decreasing\",0],\n",
    "    [\"three numbers that do not go down\",0],\n",
    "    [\"numbers that are increasing\", 1],\n",
    "    [\"the numbers are in increasing order\",1],\n",
    "    [\"the digits are in increasing order\", 1],\n",
    "    [\"each number is bigger than the previous number\",1],\n",
    "    [\"each number is strictly bigger than the prior number\",1],\n",
    "    [\"the sequence increases\",1],\n",
    "    [\"the sequence increases\",1],\n",
    "    [\"they all go up\", 1],\n",
    "    [\"the next one is greater than the prior one\", 1],\n",
    "    [\"each number is smaller than the next number\",1],\n",
    "    [\"each number is strictly less than the next number\",1],\n",
    "    [\"each number is greater than the previous number\",1],\n",
    "    [\"the numbers go up by some amount\",1],\n",
    "    [\"the numbers go up\",1],\n",
    "    [\"the numbers are in increasing order\",1],\n",
    "    [\"the digits are in increasing order\", 1],\n",
    "    [\"each number is bigger than the previous number\",1],\n",
    "    [\"each number is strictly bigger than the prior number\",1],\n",
    "    [\"the sequence increases\",1],\n",
    "    [\"the sequence increases\",1],\n",
    "    [\"they all go up\", 1],\n",
    "    [\"the next one is greater than the prior one\", 1],\n",
    "    [\"each number is smaller than the next number\",1],\n",
    "    [\"each number is strictly less than the next number\",1],\n",
    "    [\"each number is greater than the previous number\",1],\n",
    "    [\"the numbers go up by some amount\",1],\n",
    "    [\"the numbers go up\",1],\n",
    "    [\"the list strictly increases\",1],\n",
    "    [\"the next number needs to be bigger than the number before it\",1],\n",
    "    [\"the list climbs\",1],\n",
    "    [\"the sequence strictly increases\",1],\n",
    "    [\"the sequence strictly goes up\",1],\n",
    "    [\"the numbers are in increasing order\",1],\n",
    "    [\"the numbers go up by two\",0],\n",
    "    [\"each number is the next even number\",0],\n",
    "    [\"the numbers are subsequent even numbers\",0],\n",
    "    [\"the numbers are subsequent odd numbers\",0],\n",
    "    [\"each number goes up by 1\",0],\n",
    "    [\"I have six cats in my garage\",0],\n",
    "    [\"number\",0],\n",
    "    [\"evens\",0],\n",
    "    [\"odds\", 0],\n",
    "    [\"they increase\",1],\n",
    "    [\"they go up\",1],\n",
    "    [\"the rule is that\",0],\n",
    "    [\"bigger than the one before it\",1],\n",
    "    [\"add two each time\",0],\n",
    "    [\"for anyone whose tried to text or call me in the past 2 weeks\", 0],\n",
    "    [\"I got rid of that phone so I could focus on these albums\", 0],\n",
    "    [\"rules are structure for people who can’t carve their own path\", 0],\n",
    "    [\"free thinking is a super power\", 0],\n",
    "    [\"I am hyper focused on the now\", 0],\n",
    "    [\"take a walk outside fresh air is healing\", 0],\n",
    "    [\"I can not wait for electric planes\", 0],\n",
    "    [\"most fear is learned\", 0],\n",
    "    [\"energy meeting. Beings from all different backgrounds\", 0],\n",
    "    [\"in school we need to learn how magic built his business\", 0],\n",
    "    [\"we need to have open discussions and ideas on unsettled pain\", 0],\n",
    "    [\"We are all great artists\", 0],\n",
    "    [\"we've invested in 3 companies since last week\", 0],\n",
    "    [\"do meetings in different places and at different times\", 0],\n",
    "    [\"I do not agree with this\", 0],\n",
    "    [\"If someone tweeted that people who don’t drink are miserable\", 0],\n",
    "    [\"This is a good point\", 0],\n",
    "    [\"I will be doing none of the below\", 0],\n",
    "    [\"why not debate your political positions\", 0],\n",
    "    [\"positive masculinity is not toxic modern feminism is\", 0],\n",
    "    [\"the tendency to search for\", 0],\n",
    "    [\"when people falsely perceive an association\", 0],\n",
    "    [\"they are weighing up the costs of being wrong\", 0],\n",
    "    [\"rather than investigating in a neutral\", 0],\n",
    "    [\"even scientists can be prone to confirmation bias\", 0],\n",
    "    [\"maintain or strengthen beliefs in the face of contrary evidence\", 0]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GLoVE vectors from file: ./glove.6B/glove.6B.50d.txt\n",
      "loading vocabulary pickle\n",
      "vocabulary pickle loaded!\n"
     ]
    }
   ],
   "source": [
    "emb_matrix, word2id, id2word = get_glove('./glove.6B/glove.6B.50d.txt', 50) # make sure these match\n",
    "model = GameModel(id2word, word2id, emb_matrix, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1>>LOSS: 0.6700727343559265\n",
      "grad norm: 0.5542958378791809param_norm:                       31.371410369873047\n",
      "epoch: 2>>LOSS: 0.6452119946479797\n",
      "grad norm: 0.8656399846076965param_norm:                       31.374130249023438\n",
      "epoch: 3>>LOSS: 0.6045337319374084\n",
      "grad norm: 0.6062966585159302param_norm:                       31.3762149810791\n",
      "epoch: 4>>LOSS: 0.5709795355796814\n",
      "grad norm: 0.47467240691185param_norm:                       31.37963104248047\n",
      "epoch: 100>>LOSS: 0.0042997985146939754\n",
      "grad norm: 0.010538213886320591param_norm:                       32.585166931152344\n",
      "epoch: 200>>LOSS: 0.0010955327888950706\n",
      "grad norm: 0.003328164340928197param_norm:                       32.779937744140625\n",
      "epoch: 300>>LOSS: 0.0004943755338899791\n",
      "grad norm: 0.0018037512199953198param_norm:                       32.889251708984375\n",
      "epoch: 400>>LOSS: 0.000284012668998912\n",
      "grad norm: 0.0010125841945409775param_norm:                       32.966270446777344\n",
      "epoch: 500>>LOSS: 0.0001850532862590626\n",
      "grad norm: 0.0007023614598438144param_norm:                       33.02549362182617\n",
      "epoch: 600>>LOSS: 0.0001304170145886019\n",
      "grad norm: 0.0005114159430377185param_norm:                       33.073760986328125\n",
      "('three numbers that increase in their values', 1)\n",
      "('three numbers that are not strictly decreasing', 0)\n",
      "('three numbers that do not go down', 0)\n",
      "('numbers that are increasing', 1)\n",
      "('the numbers are in increasing order', 1)\n",
      "('the digits are in increasing order', 1)\n",
      "('each number is bigger than the previous number', 1)\n",
      "('each number is strictly bigger than the prior number', 1)\n",
      "('the sequence increases', 1)\n",
      "('the sequence increases', 1)\n",
      "('they all go up', 1)\n",
      "('the next one is greater than the prior one', 1)\n",
      "('each number is smaller than the next number', 1)\n",
      "('each number is strictly less than the next number', 1)\n",
      "('each number is greater than the previous number', 1)\n",
      "('the numbers go up by some amount', 1)\n",
      "('the numbers go up', 1)\n",
      "('the numbers are in increasing order', 1)\n",
      "('the digits are in increasing order', 1)\n",
      "('each number is bigger than the previous number', 1)\n",
      "('each number is strictly bigger than the prior number', 1)\n",
      "('the sequence increases', 1)\n",
      "('the sequence increases', 1)\n",
      "('they all go up', 1)\n",
      "('the next one is greater than the prior one', 1)\n",
      "('each number is smaller than the next number', 1)\n",
      "('each number is strictly less than the next number', 1)\n",
      "('each number is greater than the previous number', 1)\n",
      "('the numbers go up by some amount', 1)\n",
      "('the numbers go up', 1)\n",
      "('the list strictly increases', 1)\n",
      "('the next number needs to be bigger than the number before it', 1)\n",
      "('the list climbs', 1)\n",
      "('the sequence strictly increases', 1)\n",
      "('the sequence strictly goes up', 1)\n",
      "('the numbers are in increasing order', 1)\n",
      "('the numbers go up by two', 0)\n",
      "('each number is the next even number', 0)\n",
      "('the numbers are subsequent even numbers', 0)\n",
      "('the numbers are subsequent odd numbers', 0)\n",
      "('each number goes up by 1', 0)\n",
      "('I have six cats in my garage', 0)\n",
      "('number', 0)\n",
      "('evens', 0)\n",
      "('odds', 0)\n",
      "('they increase', 1)\n",
      "('they go up', 1)\n",
      "('the rule is that', 0)\n",
      "('bigger than the one before it', 1)\n",
      "('add two each time', 0)\n",
      "('for anyone whose tried to text or call me in the past 2 weeks', 0)\n",
      "('I got rid of that phone so I could focus on these albums', 0)\n",
      "('rules are structure for people who can’t carve their own path', 0)\n",
      "('free thinking is a super power', 0)\n",
      "('I am hyper focused on the now', 0)\n",
      "('take a walk outside fresh air is healing', 0)\n",
      "('I can not wait for electric planes', 0)\n",
      "('most fear is learned', 0)\n",
      "('energy meeting. Beings from all different backgrounds', 0)\n",
      "('in school we need to learn how magic built his business', 0)\n",
      "('we need to have open discussions and ideas on unsettled pain', 0)\n",
      "('We are all great artists', 0)\n",
      "(\"we've invested in 3 companies since last week\", 0)\n",
      "('do meetings in different places and at different times', 0)\n",
      "('I do not agree with this', 0)\n",
      "('If someone tweeted that people who don’t drink are miserable', 0)\n",
      "('This is a good point', 0)\n",
      "('I will be doing none of the below', 0)\n",
      "('why not debate your political positions', 0)\n",
      "('positive masculinity is not toxic modern feminism is', 0)\n",
      "('the tendency to search for', 0)\n",
      "('when people falsely perceive an association', 0)\n",
      "('they are weighing up the costs of being wrong', 0)\n",
      "('rather than investigating in a neutral', 0)\n",
      "('even scientists can be prone to confirmation bias', 0)\n",
      "('maintain or strengthen beliefs in the face of contrary evidence', 0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "desc, labels = zip(*data)\n",
    "desc = list(desc)\n",
    "labels = list(labels)\n",
    "model.train(desc, labels)\n",
    "for x in zip(desc, list(model.get_predictions(model.sess, *model.get_ids_and_mask(desc)))):\n",
    "  print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
